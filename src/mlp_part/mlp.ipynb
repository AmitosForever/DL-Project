{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b4c308b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader, TensorDataset\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import json\n",
    "import os\n",
    "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error\n",
    "import time\n",
    "import optuna\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "RANDOM_SEED = 50\n",
    "torch.manual_seed(RANDOM_SEED)\n",
    "np.random.seed(RANDOM_SEED)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed(RANDOM_SEED)\n",
    "\n",
    "# Device configuration\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7708cf32",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DiamondPriceMLP(nn.Module):\n",
    "    \"\"\"\n",
    "    Multi-Layer Perceptron for Diamond Price Prediction\n",
    "    \n",
    "    Architecture:\n",
    "    - Input layer (n_features)\n",
    "    - Multiple hidden layers with ReLU, BatchNorm, and Dropout\n",
    "    - Output layer (1 neuron for regression)\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, input_dim, hidden_dims, dropout_rate=0.3, use_batch_norm=True, target_mean=None):\n",
    "        super(DiamondPriceMLP, self).__init__()\n",
    "        \n",
    "        self.use_batch_norm = use_batch_norm\n",
    "        layers = []\n",
    "        \n",
    "        # Input to first hidden layer\n",
    "        prev_dim = input_dim\n",
    "        \n",
    "        for i, hidden_dim in enumerate(hidden_dims):\n",
    "            # Linear layer\n",
    "            layers.append(nn.Linear(prev_dim, hidden_dim))\n",
    "            \n",
    "            # Batch normalization (optional)\n",
    "            if use_batch_norm:\n",
    "                layers.append(nn.BatchNorm1d(hidden_dim))\n",
    "            \n",
    "            # Activation\n",
    "            layers.append(nn.ReLU())\n",
    "            \n",
    "            # Dropout\n",
    "            layers.append(nn.Dropout(dropout_rate))\n",
    "            \n",
    "            prev_dim = hidden_dim\n",
    "        \n",
    "        # Output layer (no activation for regression)\n",
    "        layers.append(nn.Linear(prev_dim, 1))\n",
    "        \n",
    "        self.network = nn.Sequential(*layers)\n",
    "        \n",
    "        # Initialize weights\n",
    "        self._initialize_weights(target_mean)\n",
    "    \n",
    "    def _initialize_weights(self, target_mean):\n",
    "        \"\"\"Initialize network weights using He initialization\"\"\"\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Linear):\n",
    "                nn.init.kaiming_normal_(m.weight, mode='fan_in', nonlinearity='relu')\n",
    "                if m.bias is not None:\n",
    "                    nn.init.constant_(m.bias, 0)\n",
    "            elif isinstance(m, nn.BatchNorm1d):\n",
    "                nn.init.constant_(m.weight, 1)\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "\n",
    "        if target_mean is not None:\n",
    "            # self.network[-1] is the final Linear(prev_dim, 1) layer\n",
    "            nn.init.constant_(self.network[-1].bias, target_mean)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.network(x).squeeze()  # Remove extra dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "90bbd4d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the current working directory (for Jupyter Notebooks)\n",
    "script_dir = os.getcwd()\n",
    "\n",
    "# Define the path to the preprocessed data directory relative to the script's location\n",
    "data_dir = os.path.join(script_dir, 'data')\n",
    "\n",
    "# Define the path to the models directory relative to the parent directory of the script's location\n",
    "models_dir = os.path.join(os.path.dirname(script_dir), 'models')\n",
    "\n",
    "# Create the models directory if it doesn't exist\n",
    "os.makedirs(models_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e6ccfc51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the preprocessed data\n",
    "X_train = np.load(f'{data_dir}/X_train_final.npy')\n",
    "X_val = np.load(f'{data_dir}/X_val_final.npy')\n",
    "X_test = np.load(f'{data_dir}/X_test_final.npy')\n",
    "\n",
    "y_train_log = np.load(f'{data_dir}/y_train_log.npy')  # Log-transformed version!\n",
    "y_val_log = np.load(f'{data_dir}/y_val_log.npy')\n",
    "y_test_log = np.load(f'{data_dir}/y_test_log.npy')\n",
    "\n",
    "# Convert numpy arrays to PyTorch tensors\n",
    "X_train_tensor = torch.tensor(X_train, dtype=torch.float32)\n",
    "X_val_tensor = torch.tensor(X_val, dtype=torch.float32)\n",
    "X_test_tensor = torch.tensor(X_test, dtype=torch.float32)\n",
    "\n",
    "y_train_log_tensor = torch.tensor(y_train_log, dtype=torch.float32).view(-1, 1)\n",
    "y_val_log_tensor = torch.tensor(y_val_log, dtype=torch.float32).view(-1, 1)\n",
    "y_test_log_tensor = torch.tensor(y_test_log, dtype=torch.float32).view(-1, 1)\n",
    "\n",
    "# Create Dataset objects\n",
    "train_dataset = TensorDataset(X_train_tensor, y_train_log_tensor)\n",
    "val_dataset = TensorDataset(X_val_tensor, y_val_log_tensor)\n",
    "test_dataset = TensorDataset(X_test_tensor, y_test_log_tensor)\n",
    "\n",
    "# Create DataLoader objects\n",
    "batch_size = 32  # You can adjust the batch size as needed\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27707caf",
   "metadata": {},
   "source": [
    "# Overfitting a single batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f641f672",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0 loss: 75.89691162109375\n",
      "epoch: 5 loss: 16.65635871887207\n",
      "epoch: 10 loss: 5.015203952789307\n",
      "epoch: 15 loss: 0.8016871213912964\n",
      "epoch: 20 loss: 1.265701413154602\n",
      "epoch: 25 loss: 1.305023431777954\n",
      "epoch: 30 loss: 0.425224244594574\n",
      "epoch: 35 loss: 0.12302149832248688\n",
      "epoch: 40 loss: 0.14183588325977325\n",
      "epoch: 45 loss: 0.15728068351745605\n",
      "epoch: 50 loss: 0.09096289426088333\n",
      "epoch: 55 loss: 0.026948552578687668\n",
      "epoch: 60 loss: 0.010629672557115555\n",
      "epoch: 65 loss: 0.008802937343716621\n",
      "epoch: 70 loss: 0.008559098467230797\n",
      "epoch: 75 loss: 0.00880097970366478\n",
      "epoch: 80 loss: 0.007069845218211412\n",
      "epoch: 85 loss: 0.005414316896349192\n",
      "epoch: 90 loss: 0.004389210604131222\n",
      "epoch: 95 loss: 0.0035448374692350626\n",
      "epoch: 100 loss: 0.003129430813714862\n",
      "epoch: 105 loss: 0.002900592051446438\n",
      "epoch: 110 loss: 0.002736336085945368\n",
      "epoch: 115 loss: 0.002666692715138197\n",
      "epoch: 120 loss: 0.0026071632746607065\n",
      "epoch: 125 loss: 0.0025668551679700613\n",
      "epoch: 130 loss: 0.0025311699137091637\n",
      "epoch: 135 loss: 0.002498699352145195\n",
      "epoch: 140 loss: 0.0024710993748158216\n",
      "epoch: 145 loss: 0.0024444847367703915\n",
      "epoch: 150 loss: 0.002419456373900175\n",
      "epoch: 155 loss: 0.002394711598753929\n",
      "epoch: 160 loss: 0.0023707314394414425\n",
      "epoch: 165 loss: 0.0023470227606594563\n",
      "epoch: 170 loss: 0.0023234104737639427\n",
      "epoch: 175 loss: 0.002299749990925193\n",
      "epoch: 180 loss: 0.002276006620377302\n",
      "epoch: 185 loss: 0.0022521314676851034\n",
      "epoch: 190 loss: 0.0022281361743807793\n",
      "epoch: 195 loss: 0.0022040996700525284\n",
      "epoch: 200 loss: 0.0021800482645630836\n",
      "epoch: 205 loss: 0.002155968686565757\n",
      "epoch: 210 loss: 0.002132002031430602\n",
      "epoch: 215 loss: 0.00210821395739913\n",
      "epoch: 220 loss: 0.002084229839965701\n",
      "epoch: 225 loss: 0.002060206839814782\n",
      "epoch: 230 loss: 0.002036178018897772\n",
      "epoch: 235 loss: 0.002012497978284955\n",
      "epoch: 240 loss: 0.0019887255039066076\n",
      "epoch: 245 loss: 0.0019648924935609102\n",
      "epoch: 250 loss: 0.0019410671666264534\n",
      "epoch: 255 loss: 0.001917321584187448\n",
      "epoch: 260 loss: 0.0018938537687063217\n",
      "epoch: 265 loss: 0.0018703939858824015\n",
      "epoch: 270 loss: 0.001846909406594932\n",
      "epoch: 275 loss: 0.0018237214535474777\n",
      "epoch: 280 loss: 0.0018007777398452163\n",
      "epoch: 285 loss: 0.0017780582420527935\n",
      "epoch: 290 loss: 0.0017552073113620281\n",
      "epoch: 295 loss: 0.0017325070220977068\n",
      "epoch: 300 loss: 0.0017099400283768773\n",
      "epoch: 305 loss: 0.0016877955058589578\n",
      "epoch: 310 loss: 0.0016657154774293303\n",
      "epoch: 315 loss: 0.0016436047153547406\n",
      "epoch: 320 loss: 0.0016216711373999715\n",
      "epoch: 325 loss: 0.0016000823816284537\n",
      "epoch: 330 loss: 0.0015786201693117619\n",
      "epoch: 335 loss: 0.0015573601704090834\n",
      "epoch: 340 loss: 0.0015362072736024857\n",
      "epoch: 345 loss: 0.001515279640443623\n",
      "epoch: 350 loss: 0.001494729658588767\n",
      "epoch: 355 loss: 0.0014743125066161156\n",
      "epoch: 360 loss: 0.001453988952562213\n",
      "epoch: 365 loss: 0.0014338786713778973\n",
      "epoch: 370 loss: 0.0014141956344246864\n",
      "epoch: 375 loss: 0.0013946759281679988\n",
      "epoch: 380 loss: 0.0013751802034676075\n",
      "epoch: 385 loss: 0.0013560815714299679\n",
      "epoch: 390 loss: 0.0013372718822211027\n",
      "epoch: 395 loss: 0.0013187187723815441\n",
      "epoch: 400 loss: 0.001300295116379857\n",
      "epoch: 405 loss: 0.0012820980045944452\n",
      "epoch: 410 loss: 0.0012642411747947335\n",
      "epoch: 415 loss: 0.0012468673521652818\n",
      "epoch: 420 loss: 0.0012295626802369952\n",
      "epoch: 425 loss: 0.0012124242493882775\n",
      "epoch: 430 loss: 0.0011954595101997256\n",
      "epoch: 435 loss: 0.001178814098238945\n",
      "epoch: 440 loss: 0.0011625802144408226\n",
      "epoch: 445 loss: 0.0011464820709079504\n",
      "epoch: 450 loss: 0.0011304987128823996\n",
      "epoch: 455 loss: 0.001114842016249895\n",
      "epoch: 460 loss: 0.0010991821764037013\n",
      "epoch: 465 loss: 0.0010841111652553082\n",
      "epoch: 470 loss: 0.0010691587813198566\n",
      "epoch: 475 loss: 0.0010542751988396049\n",
      "epoch: 480 loss: 0.001039778464473784\n",
      "epoch: 485 loss: 0.0010255007073283195\n",
      "epoch: 490 loss: 0.001011344138532877\n",
      "epoch: 495 loss: 0.0009936413262039423\n",
      "epoch: 500 loss: 0.0009795803343877196\n",
      "epoch: 505 loss: 0.0009659004281274974\n",
      "epoch: 510 loss: 0.0009526985813863575\n",
      "epoch: 515 loss: 0.0009397235698997974\n",
      "epoch: 520 loss: 0.0009196940809488297\n",
      "epoch: 525 loss: 0.0009011998772621155\n",
      "epoch: 530 loss: 0.000888525159098208\n",
      "epoch: 535 loss: 0.0008761570788919926\n",
      "epoch: 540 loss: 0.0008642907487228513\n",
      "epoch: 545 loss: 0.0008527414756827056\n",
      "epoch: 550 loss: 0.0008413600735366344\n",
      "epoch: 555 loss: 0.0008302693022415042\n",
      "epoch: 560 loss: 0.0008194178808480501\n",
      "epoch: 565 loss: 0.000808901502750814\n",
      "epoch: 570 loss: 0.0007984824478626251\n",
      "epoch: 575 loss: 0.0007882174104452133\n",
      "epoch: 580 loss: 0.0007784439949318767\n",
      "epoch: 585 loss: 0.0007686970639042556\n",
      "epoch: 590 loss: 0.000759097863920033\n",
      "epoch: 595 loss: 0.0007497175829485059\n",
      "epoch: 600 loss: 0.0007408009259961545\n",
      "epoch: 605 loss: 0.0007317494601011276\n",
      "epoch: 610 loss: 0.000722964876331389\n",
      "epoch: 615 loss: 0.0007144499686546624\n",
      "epoch: 620 loss: 0.0007061624201014638\n",
      "epoch: 625 loss: 0.0006980618927627802\n",
      "epoch: 630 loss: 0.0006902380846440792\n",
      "epoch: 635 loss: 0.0006824088632129133\n",
      "epoch: 640 loss: 0.000674787734169513\n",
      "epoch: 645 loss: 0.0006668168352916837\n",
      "epoch: 650 loss: 0.0006582963978871703\n",
      "epoch: 655 loss: 0.0006514859851449728\n",
      "epoch: 660 loss: 0.0006447238847613335\n",
      "epoch: 665 loss: 0.0006381293060258031\n",
      "epoch: 670 loss: 0.0006316659273579717\n",
      "epoch: 675 loss: 0.0006255869520828128\n",
      "epoch: 680 loss: 0.0006195941241458058\n",
      "epoch: 685 loss: 0.0006136843585409224\n",
      "epoch: 690 loss: 0.0006078832084313035\n",
      "epoch: 695 loss: 0.0006022556917741895\n",
      "epoch: 700 loss: 0.000596814788877964\n",
      "epoch: 705 loss: 0.0005914511857554317\n",
      "epoch: 710 loss: 0.0005862569669261575\n",
      "epoch: 715 loss: 0.0005811965093016624\n",
      "epoch: 720 loss: 0.000576348858885467\n",
      "epoch: 725 loss: 0.0005715696606785059\n",
      "epoch: 730 loss: 0.0005668562953360379\n",
      "epoch: 735 loss: 0.0005622408934868872\n",
      "epoch: 740 loss: 0.0005577641422860324\n",
      "epoch: 745 loss: 0.0005535472300834954\n",
      "epoch: 750 loss: 0.000549406569916755\n",
      "epoch: 755 loss: 0.0005453515332192183\n",
      "epoch: 760 loss: 0.000541351386345923\n",
      "epoch: 765 loss: 0.0005374877946451306\n",
      "epoch: 770 loss: 0.0005337806069292128\n",
      "epoch: 775 loss: 0.0005300893681123853\n",
      "epoch: 780 loss: 0.0005264892242848873\n",
      "epoch: 785 loss: 0.000523064867593348\n",
      "epoch: 790 loss: 0.0005197433056309819\n",
      "epoch: 795 loss: 0.0005165115580894053\n",
      "epoch: 800 loss: 0.0005133311497047544\n",
      "epoch: 805 loss: 0.0005102775758132339\n",
      "epoch: 810 loss: 0.0005073357024230063\n",
      "epoch: 815 loss: 0.0005044147255830467\n",
      "epoch: 820 loss: 0.0005015571368858218\n",
      "epoch: 825 loss: 0.0004987978609278798\n",
      "epoch: 830 loss: 0.0004961185622960329\n",
      "epoch: 835 loss: 0.0004935722099617124\n",
      "epoch: 840 loss: 0.0004911138094030321\n",
      "epoch: 845 loss: 0.0004888269468210638\n",
      "epoch: 850 loss: 0.00048644671915099025\n",
      "epoch: 855 loss: 0.00048416946083307266\n",
      "epoch: 860 loss: 0.0004819864116143435\n",
      "epoch: 865 loss: 0.0004798371810466051\n",
      "epoch: 870 loss: 0.0004777482245117426\n",
      "epoch: 875 loss: 0.0004757231508847326\n",
      "epoch: 880 loss: 0.00047379054012708366\n",
      "epoch: 885 loss: 0.000471913896035403\n",
      "epoch: 890 loss: 0.0004700941499322653\n",
      "epoch: 895 loss: 0.0004683037695940584\n",
      "epoch: 900 loss: 0.00046655774349346757\n",
      "epoch: 905 loss: 0.0004648800240829587\n",
      "epoch: 910 loss: 0.00046333667705766857\n",
      "epoch: 915 loss: 0.0004617947561200708\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[11]\u001b[39m\u001b[32m, line 45\u001b[39m\n\u001b[32m     43\u001b[39m optimizer.zero_grad()  \u001b[38;5;66;03m# clean the gradients from previous iteration, clears the `tensor.grad` field (tensor.grad=0)\u001b[39;00m\n\u001b[32m     44\u001b[39m loss.backward()  \u001b[38;5;66;03m# autograd backward to calculate gradients, assigns the `tensor.grad` field (e.g., tensor.grad=0.27)\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m45\u001b[39m \u001b[43moptimizer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# apply update to the weights, applies the gradient update rule of the optimizer (param=param - lr * grad)\u001b[39;00m\n\u001b[32m     47\u001b[39m epoch_losses.append(loss.item())\n\u001b[32m     49\u001b[39m \u001b[38;5;66;03m# Store batch data for visualization\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/dl_project/lib/python3.12/site-packages/torch/optim/optimizer.py:493\u001b[39m, in \u001b[36mOptimizer.profile_hook_step.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    488\u001b[39m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    489\u001b[39m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[32m    490\u001b[39m                 \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m must return None or a tuple of (new_args, new_kwargs), but got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresult\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    491\u001b[39m             )\n\u001b[32m--> \u001b[39m\u001b[32m493\u001b[39m out = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    494\u001b[39m \u001b[38;5;28mself\u001b[39m._optimizer_step_code()\n\u001b[32m    496\u001b[39m \u001b[38;5;66;03m# call optimizer step post hooks\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/dl_project/lib/python3.12/site-packages/torch/optim/optimizer.py:91\u001b[39m, in \u001b[36m_use_grad_for_differentiable.<locals>._use_grad\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m     89\u001b[39m     torch.set_grad_enabled(\u001b[38;5;28mself\u001b[39m.defaults[\u001b[33m\"\u001b[39m\u001b[33mdifferentiable\u001b[39m\u001b[33m\"\u001b[39m])\n\u001b[32m     90\u001b[39m     torch._dynamo.graph_break()\n\u001b[32m---> \u001b[39m\u001b[32m91\u001b[39m     ret = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     92\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m     93\u001b[39m     torch._dynamo.graph_break()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/dl_project/lib/python3.12/site-packages/torch/optim/adam.py:244\u001b[39m, in \u001b[36mAdam.step\u001b[39m\u001b[34m(self, closure)\u001b[39m\n\u001b[32m    232\u001b[39m     beta1, beta2 = group[\u001b[33m\"\u001b[39m\u001b[33mbetas\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m    234\u001b[39m     has_complex = \u001b[38;5;28mself\u001b[39m._init_group(\n\u001b[32m    235\u001b[39m         group,\n\u001b[32m    236\u001b[39m         params_with_grad,\n\u001b[32m   (...)\u001b[39m\u001b[32m    241\u001b[39m         state_steps,\n\u001b[32m    242\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m244\u001b[39m     adam(\n\u001b[32m    245\u001b[39m         params_with_grad,\n\u001b[32m    246\u001b[39m         grads,\n\u001b[32m    247\u001b[39m         exp_avgs,\n\u001b[32m    248\u001b[39m         exp_avg_sqs,\n\u001b[32m    249\u001b[39m         max_exp_avg_sqs,\n\u001b[32m    250\u001b[39m         state_steps,\n\u001b[32m    251\u001b[39m         amsgrad=group[\u001b[33m\"\u001b[39m\u001b[33mamsgrad\u001b[39m\u001b[33m\"\u001b[39m],\n\u001b[32m    252\u001b[39m         has_complex=has_complex,\n\u001b[32m    253\u001b[39m         beta1=beta1,\n\u001b[32m    254\u001b[39m         beta2=beta2,\n\u001b[32m    255\u001b[39m         lr=group[\u001b[33m\"\u001b[39m\u001b[33mlr\u001b[39m\u001b[33m\"\u001b[39m],\n\u001b[32m    256\u001b[39m         weight_decay=group[\u001b[33m\"\u001b[39m\u001b[33mweight_decay\u001b[39m\u001b[33m\"\u001b[39m],\n\u001b[32m    257\u001b[39m         eps=group[\u001b[33m\"\u001b[39m\u001b[33meps\u001b[39m\u001b[33m\"\u001b[39m],\n\u001b[32m    258\u001b[39m         maximize=group[\u001b[33m\"\u001b[39m\u001b[33mmaximize\u001b[39m\u001b[33m\"\u001b[39m],\n\u001b[32m    259\u001b[39m         foreach=group[\u001b[33m\"\u001b[39m\u001b[33mforeach\u001b[39m\u001b[33m\"\u001b[39m],\n\u001b[32m    260\u001b[39m         capturable=group[\u001b[33m\"\u001b[39m\u001b[33mcapturable\u001b[39m\u001b[33m\"\u001b[39m],\n\u001b[32m    261\u001b[39m         differentiable=group[\u001b[33m\"\u001b[39m\u001b[33mdifferentiable\u001b[39m\u001b[33m\"\u001b[39m],\n\u001b[32m    262\u001b[39m         fused=group[\u001b[33m\"\u001b[39m\u001b[33mfused\u001b[39m\u001b[33m\"\u001b[39m],\n\u001b[32m    263\u001b[39m         grad_scale=\u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mgrad_scale\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[32m    264\u001b[39m         found_inf=\u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mfound_inf\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[32m    265\u001b[39m     )\n\u001b[32m    267\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m loss\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "# Overfit a single batch for debugging\n",
    "\n",
    "# Create DataLoader objects\n",
    "batch_size = 32  # You can adjust the batch size as needed\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# Get a single batch to overfit\n",
    "single_batch = next(iter(train_loader))\n",
    "features, targets = single_batch\n",
    "features = features.to(device)\n",
    "targets = targets.to(device)\n",
    "\n",
    "# define hyper-parmeters and create our model\n",
    "num_features = 55\n",
    "output_dim = 1\n",
    "batch_size = 128\n",
    "learning_rate = 0.01\n",
    "num_epochs = 2000\n",
    "# loss criterion\n",
    "criterion = nn.MSELoss()\n",
    "# model\n",
    "model = DiamondPriceMLP(num_features, [128, 64, 32, 16], 0, False).to(device)\n",
    "# optimizer\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# training loop for the model\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()  # change the mode to training, activating layers like DropOut and BatchNorm, if there are any\n",
    "    epoch_losses = []\n",
    "    \n",
    "    # send data to device\n",
    "    features = features.to(device)\n",
    "    targets = targets.to(device)\n",
    "    \n",
    "    # forward pass\n",
    "    output = model(features)  # calls model.forward(features)\n",
    "    # loss\n",
    "    loss = criterion(output.view(-1), targets.view(-1))\n",
    "    # backward pass\n",
    "    optimizer.zero_grad()  # clean the gradients from previous iteration, clears the `tensor.grad` field (tensor.grad=0)\n",
    "    loss.backward()  # autograd backward to calculate gradients, assigns the `tensor.grad` field (e.g., tensor.grad=0.27)\n",
    "    optimizer.step()  # apply update to the weights, applies the gradient update rule of the optimizer (param=param - lr * grad)\n",
    "    \n",
    "    epoch_losses.append(loss.item())\n",
    "    \n",
    "    # Store batch data for visualization\n",
    "    if epoch == num_epochs - 1:  # Only store in the first epoch\n",
    "        batch_features = features.cpu().numpy()\n",
    "        batch_targets = targets.cpu().numpy()\n",
    "        batch_predictions = output.detach().cpu().numpy()\n",
    "    \"\"\"\n",
    "    if epoch == 500 or epoch == 1000 or epoch == 1500:\n",
    "        for param_group in optimizer.param_groups:\n",
    "            param_group['lr'] = param_group['lr'] * 0.1  # Reduce by 10x\n",
    "            print(f\"Learning rate reduced to: {param_group['lr']}\")\n",
    "    \"\"\"\n",
    "    if epoch % 5 == 0:\n",
    "        print(f'epoch: {epoch} loss: {np.mean(epoch_losses)}')\n",
    "\n",
    "# Visualization\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "# Plot true labels\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(batch_targets, label='True Labels', marker='o')\n",
    "plt.title('Batch True Labels')\n",
    "plt.xlabel('Sample Index')\n",
    "plt.ylabel('Label Value')\n",
    "plt.legend()\n",
    "\n",
    "# Plot predictions\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(batch_predictions, label='Predictions', marker='x')\n",
    "plt.title('Batch Predictions')\n",
    "plt.xlabel('Sample Index')\n",
    "plt.ylabel('Prediction Value')\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d759a80a",
   "metadata": {},
   "source": [
    "# A regular run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "b258df9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create DataLoader objects\n",
    "batch_size = 256  # You can adjust the batch size as needed\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ab25ecad",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_mean = np.mean(y_train_log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "07739df9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define hyper-parmeters and create our model\n",
    "num_features = 55\n",
    "output_dim = 1\n",
    "batch_size = 128\n",
    "learning_rate = 0.01\n",
    "num_epochs = 500\n",
    "# train loss criterion\n",
    "train_criterion = nn.HuberLoss(delta=0.2)\n",
    "# validtion loss criterion\n",
    "val_criterion = nn.MSELoss()\n",
    "# model\n",
    "model = DiamondPriceMLP(num_features, [512, 256, 256, 128, 128, 64, 32], 0.1, False, target_mean=np.mean(y_train_log)).to(device)\n",
    "# optimizer\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "# schedular\n",
    "\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "    optimizer,\n",
    "    mode='min',        # Minimize val loss\n",
    "    factor=0.5,        # Multiply LR by 0.5 when triggered\n",
    "    patience=40,       # Wait 20 epochs before reducing\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "7f3a5b90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: Train Loss = 0.028830, Val Loss (log) = 0.102622, Val RMSE (real $) = $471,721.09, LR=[0.01]\n",
      "Epoch 5: Train Loss = 0.019155, Val Loss (log) = 0.049184, Val RMSE (real $) = $11,335.93, LR=[0.01]\n",
      "Epoch 10: Train Loss = 0.019614, Val Loss (log) = 0.087732, Val RMSE (real $) = $18,464.10, LR=[0.01]\n",
      "Epoch 15: Train Loss = 0.020652, Val Loss (log) = 0.061956, Val RMSE (real $) = $11,778.42, LR=[0.01]\n",
      "Epoch 20: Train Loss = 0.021915, Val Loss (log) = 0.084065, Val RMSE (real $) = $18,800.04, LR=[0.01]\n",
      "Epoch 25: Train Loss = 0.024125, Val Loss (log) = 0.079795, Val RMSE (real $) = $16,732.78, LR=[0.01]\n",
      "Epoch 30: Train Loss = 0.025661, Val Loss (log) = 0.081030, Val RMSE (real $) = $18,712.11, LR=[0.01]\n",
      "Epoch 35: Train Loss = 0.034228, Val Loss (log) = 0.108263, Val RMSE (real $) = $18,356.05, LR=[0.01]\n",
      "Epoch 40: Train Loss = 0.037028, Val Loss (log) = 0.106933, Val RMSE (real $) = $17,417.99, LR=[0.01]\n",
      "Epoch 45: Train Loss = 0.051372, Val Loss (log) = 0.413418, Val RMSE (real $) = $24,411.55, LR=[0.01]\n",
      "Epoch 50: Train Loss = 0.042159, Val Loss (log) = 0.108040, Val RMSE (real $) = $18,901.63, LR=[0.005]\n",
      "Epoch 55: Train Loss = 0.039032, Val Loss (log) = 0.108244, Val RMSE (real $) = $19,742.21, LR=[0.005]\n",
      "Epoch 60: Train Loss = 0.039216, Val Loss (log) = 0.102212, Val RMSE (real $) = $19,484.27, LR=[0.005]\n",
      "Epoch 65: Train Loss = 0.036594, Val Loss (log) = 0.106417, Val RMSE (real $) = $17,626.13, LR=[0.005]\n",
      "Epoch 70: Train Loss = 0.033432, Val Loss (log) = 0.119939, Val RMSE (real $) = $20,293.09, LR=[0.005]\n",
      "Epoch 75: Train Loss = 0.036095, Val Loss (log) = 0.113321, Val RMSE (real $) = $19,572.51, LR=[0.005]\n",
      "Epoch 80: Train Loss = 0.036373, Val Loss (log) = 0.065047, Val RMSE (real $) = $16,472.15, LR=[0.005]\n",
      "Epoch 85: Train Loss = 0.032060, Val Loss (log) = 0.083430, Val RMSE (real $) = $18,853.31, LR=[0.005]\n",
      "Epoch 90: Train Loss = 0.031723, Val Loss (log) = 0.098261, Val RMSE (real $) = $19,389.71, LR=[0.0025]\n",
      "Epoch 95: Train Loss = 0.029822, Val Loss (log) = 0.089152, Val RMSE (real $) = $18,386.14, LR=[0.0025]\n",
      "Epoch 100: Train Loss = 0.029825, Val Loss (log) = 0.134255, Val RMSE (real $) = $20,499.85, LR=[0.0025]\n",
      "Epoch 105: Train Loss = 0.034896, Val Loss (log) = 0.111630, Val RMSE (real $) = $19,961.82, LR=[0.0025]\n",
      "Epoch 110: Train Loss = 0.029581, Val Loss (log) = 0.132236, Val RMSE (real $) = $21,421.68, LR=[0.0025]\n",
      "Epoch 115: Train Loss = 0.028211, Val Loss (log) = 0.118400, Val RMSE (real $) = $20,401.94, LR=[0.0025]\n",
      "Epoch 120: Train Loss = 0.025221, Val Loss (log) = 0.092528, Val RMSE (real $) = $19,140.02, LR=[0.0025]\n",
      "Epoch 125: Train Loss = 0.025436, Val Loss (log) = 0.098711, Val RMSE (real $) = $19,939.00, LR=[0.0025]\n",
      "Epoch 130: Train Loss = 0.024611, Val Loss (log) = 0.101848, Val RMSE (real $) = $20,012.29, LR=[0.00125]\n",
      "Epoch 135: Train Loss = 0.024219, Val Loss (log) = 0.112888, Val RMSE (real $) = $20,784.97, LR=[0.00125]\n",
      "Epoch 140: Train Loss = 0.023958, Val Loss (log) = 0.082691, Val RMSE (real $) = $18,972.33, LR=[0.00125]\n",
      "Epoch 145: Train Loss = 0.023307, Val Loss (log) = 0.097234, Val RMSE (real $) = $19,550.39, LR=[0.00125]\n",
      "Epoch 150: Train Loss = 0.023173, Val Loss (log) = 0.096067, Val RMSE (real $) = $19,277.99, LR=[0.00125]\n",
      "Epoch 155: Train Loss = 0.023381, Val Loss (log) = 0.119989, Val RMSE (real $) = $20,537.47, LR=[0.00125]\n",
      "Epoch 160: Train Loss = 0.023116, Val Loss (log) = 0.093446, Val RMSE (real $) = $19,516.56, LR=[0.00125]\n",
      "Epoch 165: Train Loss = 0.023378, Val Loss (log) = 0.102396, Val RMSE (real $) = $19,704.26, LR=[0.00125]\n",
      "Epoch 170: Train Loss = 0.022972, Val Loss (log) = 0.119725, Val RMSE (real $) = $20,777.05, LR=[0.000625]\n",
      "Epoch 175: Train Loss = 0.022856, Val Loss (log) = 0.108396, Val RMSE (real $) = $20,260.08, LR=[0.000625]\n",
      "Epoch 180: Train Loss = 0.022871, Val Loss (log) = 0.109247, Val RMSE (real $) = $20,410.93, LR=[0.000625]\n",
      "Epoch 185: Train Loss = 0.022829, Val Loss (log) = 0.097979, Val RMSE (real $) = $19,436.92, LR=[0.000625]\n",
      "Epoch 190: Train Loss = 0.022795, Val Loss (log) = 0.123611, Val RMSE (real $) = $20,911.92, LR=[0.000625]\n",
      "Epoch 195: Train Loss = 0.022924, Val Loss (log) = 0.091650, Val RMSE (real $) = $18,929.80, LR=[0.000625]\n",
      "Epoch 200: Train Loss = 0.022799, Val Loss (log) = 0.099563, Val RMSE (real $) = $19,591.28, LR=[0.000625]\n",
      "Epoch 205: Train Loss = 0.022683, Val Loss (log) = 0.109558, Val RMSE (real $) = $20,182.16, LR=[0.000625]\n",
      "Epoch 210: Train Loss = 0.022537, Val Loss (log) = 0.115645, Val RMSE (real $) = $20,563.52, LR=[0.0003125]\n",
      "Epoch 215: Train Loss = 0.022262, Val Loss (log) = 0.104011, Val RMSE (real $) = $19,789.37, LR=[0.0003125]\n",
      "Epoch 220: Train Loss = 0.022262, Val Loss (log) = 0.116448, Val RMSE (real $) = $20,475.73, LR=[0.0003125]\n",
      "Epoch 225: Train Loss = 0.022339, Val Loss (log) = 0.110064, Val RMSE (real $) = $20,249.37, LR=[0.0003125]\n",
      "Epoch 230: Train Loss = 0.022228, Val Loss (log) = 0.110060, Val RMSE (real $) = $19,978.68, LR=[0.0003125]\n",
      "Epoch 235: Train Loss = 0.022380, Val Loss (log) = 0.105764, Val RMSE (real $) = $19,894.26, LR=[0.0003125]\n",
      "Epoch 240: Train Loss = 0.022506, Val Loss (log) = 0.115692, Val RMSE (real $) = $20,463.79, LR=[0.0003125]\n",
      "Epoch 245: Train Loss = 0.022651, Val Loss (log) = 0.108319, Val RMSE (real $) = $20,115.47, LR=[0.0003125]\n",
      "Epoch 250: Train Loss = 0.022598, Val Loss (log) = 0.129605, Val RMSE (real $) = $20,876.26, LR=[0.0003125]\n",
      "Epoch 255: Train Loss = 0.022558, Val Loss (log) = 0.119024, Val RMSE (real $) = $20,504.09, LR=[0.00015625]\n",
      "Epoch 260: Train Loss = 0.022464, Val Loss (log) = 0.120507, Val RMSE (real $) = $20,583.60, LR=[0.00015625]\n",
      "Epoch 265: Train Loss = 0.022535, Val Loss (log) = 0.122952, Val RMSE (real $) = $20,702.38, LR=[0.00015625]\n",
      "Epoch 270: Train Loss = 0.022471, Val Loss (log) = 0.126649, Val RMSE (real $) = $20,880.69, LR=[0.00015625]\n",
      "Epoch 275: Train Loss = 0.022464, Val Loss (log) = 0.114628, Val RMSE (real $) = $20,315.87, LR=[0.00015625]\n",
      "Epoch 280: Train Loss = 0.022581, Val Loss (log) = 0.122588, Val RMSE (real $) = $20,709.15, LR=[0.00015625]\n",
      "Epoch 285: Train Loss = 0.022451, Val Loss (log) = 0.121144, Val RMSE (real $) = $20,545.76, LR=[0.00015625]\n",
      "Epoch 290: Train Loss = 0.022624, Val Loss (log) = 0.124541, Val RMSE (real $) = $20,779.09, LR=[0.00015625]\n",
      "Epoch 295: Train Loss = 0.022443, Val Loss (log) = 0.115979, Val RMSE (real $) = $20,245.74, LR=[7.8125e-05]\n",
      "Epoch 300: Train Loss = 0.022440, Val Loss (log) = 0.120381, Val RMSE (real $) = $20,518.55, LR=[7.8125e-05]\n",
      "Epoch 305: Train Loss = 0.022148, Val Loss (log) = 0.113822, Val RMSE (real $) = $20,360.21, LR=[7.8125e-05]\n",
      "Epoch 310: Train Loss = 0.022290, Val Loss (log) = 0.120035, Val RMSE (real $) = $20,489.98, LR=[7.8125e-05]\n",
      "Epoch 315: Train Loss = 0.022252, Val Loss (log) = 0.123679, Val RMSE (real $) = $20,705.73, LR=[7.8125e-05]\n",
      "Epoch 320: Train Loss = 0.022388, Val Loss (log) = 0.119993, Val RMSE (real $) = $20,577.46, LR=[7.8125e-05]\n",
      "Epoch 325: Train Loss = 0.022456, Val Loss (log) = 0.119238, Val RMSE (real $) = $20,560.78, LR=[7.8125e-05]\n",
      "Epoch 330: Train Loss = 0.022441, Val Loss (log) = 0.120660, Val RMSE (real $) = $20,576.50, LR=[7.8125e-05]\n",
      "Epoch 335: Train Loss = 0.022383, Val Loss (log) = 0.122272, Val RMSE (real $) = $20,620.63, LR=[3.90625e-05]\n",
      "Epoch 340: Train Loss = 0.022636, Val Loss (log) = 0.115866, Val RMSE (real $) = $20,422.39, LR=[3.90625e-05]\n",
      "Epoch 345: Train Loss = 0.022496, Val Loss (log) = 0.120831, Val RMSE (real $) = $20,652.91, LR=[3.90625e-05]\n",
      "Epoch 350: Train Loss = 0.022299, Val Loss (log) = 0.120951, Val RMSE (real $) = $20,627.04, LR=[3.90625e-05]\n",
      "Epoch 355: Train Loss = 0.022434, Val Loss (log) = 0.120514, Val RMSE (real $) = $20,562.17, LR=[3.90625e-05]\n",
      "Epoch 360: Train Loss = 0.022355, Val Loss (log) = 0.116292, Val RMSE (real $) = $20,398.25, LR=[3.90625e-05]\n",
      "Epoch 365: Train Loss = 0.022472, Val Loss (log) = 0.122605, Val RMSE (real $) = $20,686.15, LR=[3.90625e-05]\n",
      "Epoch 370: Train Loss = 0.022115, Val Loss (log) = 0.121099, Val RMSE (real $) = $20,660.83, LR=[3.90625e-05]\n",
      "Epoch 375: Train Loss = 0.022369, Val Loss (log) = 0.117022, Val RMSE (real $) = $20,451.38, LR=[1.953125e-05]\n",
      "Epoch 380: Train Loss = 0.022330, Val Loss (log) = 0.119937, Val RMSE (real $) = $20,560.84, LR=[1.953125e-05]\n",
      "Epoch 385: Train Loss = 0.022430, Val Loss (log) = 0.121647, Val RMSE (real $) = $20,626.53, LR=[1.953125e-05]\n",
      "Epoch 390: Train Loss = 0.022371, Val Loss (log) = 0.118909, Val RMSE (real $) = $20,535.35, LR=[1.953125e-05]\n",
      "Epoch 395: Train Loss = 0.022505, Val Loss (log) = 0.121567, Val RMSE (real $) = $20,656.58, LR=[1.953125e-05]\n",
      "Epoch 400: Train Loss = 0.022486, Val Loss (log) = 0.119993, Val RMSE (real $) = $20,571.09, LR=[1.953125e-05]\n",
      "Epoch 405: Train Loss = 0.022621, Val Loss (log) = 0.121951, Val RMSE (real $) = $20,630.69, LR=[1.953125e-05]\n",
      "Epoch 410: Train Loss = 0.022331, Val Loss (log) = 0.121347, Val RMSE (real $) = $20,600.21, LR=[1.953125e-05]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[39]\u001b[39m\u001b[32m, line 20\u001b[39m\n\u001b[32m     18\u001b[39m     loss.backward()  \u001b[38;5;66;03m# autograd backward to calculate gradients, assigns the `tensor.grad` field (e.g., tensor.grad=0.27)\u001b[39;00m\n\u001b[32m     19\u001b[39m     torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=\u001b[32m1.0\u001b[39m)  \u001b[38;5;66;03m# â† Gradient clipping\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m20\u001b[39m     \u001b[43moptimizer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# apply update to the weights, applies the gradient update rule of the optimizer (param=param - lr * grad)\u001b[39;00m\n\u001b[32m     22\u001b[39m     train_losses.append(loss.item())\n\u001b[32m     24\u001b[39m model.eval()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/dl_project/lib/python3.12/site-packages/torch/optim/optimizer.py:493\u001b[39m, in \u001b[36mOptimizer.profile_hook_step.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    488\u001b[39m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    489\u001b[39m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[32m    490\u001b[39m                 \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m must return None or a tuple of (new_args, new_kwargs), but got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresult\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    491\u001b[39m             )\n\u001b[32m--> \u001b[39m\u001b[32m493\u001b[39m out = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    494\u001b[39m \u001b[38;5;28mself\u001b[39m._optimizer_step_code()\n\u001b[32m    496\u001b[39m \u001b[38;5;66;03m# call optimizer step post hooks\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/dl_project/lib/python3.12/site-packages/torch/optim/optimizer.py:91\u001b[39m, in \u001b[36m_use_grad_for_differentiable.<locals>._use_grad\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m     89\u001b[39m     torch.set_grad_enabled(\u001b[38;5;28mself\u001b[39m.defaults[\u001b[33m\"\u001b[39m\u001b[33mdifferentiable\u001b[39m\u001b[33m\"\u001b[39m])\n\u001b[32m     90\u001b[39m     torch._dynamo.graph_break()\n\u001b[32m---> \u001b[39m\u001b[32m91\u001b[39m     ret = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     92\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m     93\u001b[39m     torch._dynamo.graph_break()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/dl_project/lib/python3.12/site-packages/torch/optim/adam.py:244\u001b[39m, in \u001b[36mAdam.step\u001b[39m\u001b[34m(self, closure)\u001b[39m\n\u001b[32m    232\u001b[39m     beta1, beta2 = group[\u001b[33m\"\u001b[39m\u001b[33mbetas\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m    234\u001b[39m     has_complex = \u001b[38;5;28mself\u001b[39m._init_group(\n\u001b[32m    235\u001b[39m         group,\n\u001b[32m    236\u001b[39m         params_with_grad,\n\u001b[32m   (...)\u001b[39m\u001b[32m    241\u001b[39m         state_steps,\n\u001b[32m    242\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m244\u001b[39m     \u001b[43madam\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    245\u001b[39m \u001b[43m        \u001b[49m\u001b[43mparams_with_grad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    246\u001b[39m \u001b[43m        \u001b[49m\u001b[43mgrads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    247\u001b[39m \u001b[43m        \u001b[49m\u001b[43mexp_avgs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    248\u001b[39m \u001b[43m        \u001b[49m\u001b[43mexp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    249\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmax_exp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    250\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstate_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    251\u001b[39m \u001b[43m        \u001b[49m\u001b[43mamsgrad\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mamsgrad\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    252\u001b[39m \u001b[43m        \u001b[49m\u001b[43mhas_complex\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhas_complex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    253\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbeta1\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbeta1\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    254\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbeta2\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbeta2\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    255\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlr\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mlr\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    256\u001b[39m \u001b[43m        \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mweight_decay\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    257\u001b[39m \u001b[43m        \u001b[49m\u001b[43meps\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43meps\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    258\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmaximize\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmaximize\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    259\u001b[39m \u001b[43m        \u001b[49m\u001b[43mforeach\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mforeach\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    260\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcapturable\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcapturable\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    261\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdifferentiable\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mdifferentiable\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    262\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfused\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfused\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    263\u001b[39m \u001b[43m        \u001b[49m\u001b[43mgrad_scale\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mgrad_scale\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    264\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfound_inf\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfound_inf\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    265\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    267\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m loss\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/dl_project/lib/python3.12/site-packages/torch/optim/optimizer.py:154\u001b[39m, in \u001b[36m_disable_dynamo_if_unsupported.<locals>.wrapper.<locals>.maybe_fallback\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    152\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m disabled_func(*args, **kwargs)\n\u001b[32m    153\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m154\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/dl_project/lib/python3.12/site-packages/torch/optim/adam.py:876\u001b[39m, in \u001b[36madam\u001b[39m\u001b[34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, foreach, capturable, differentiable, fused, grad_scale, found_inf, has_complex, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize)\u001b[39m\n\u001b[32m    873\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    874\u001b[39m     func = _single_tensor_adam\n\u001b[32m--> \u001b[39m\u001b[32m876\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    877\u001b[39m \u001b[43m    \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    878\u001b[39m \u001b[43m    \u001b[49m\u001b[43mgrads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    879\u001b[39m \u001b[43m    \u001b[49m\u001b[43mexp_avgs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    880\u001b[39m \u001b[43m    \u001b[49m\u001b[43mexp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    881\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmax_exp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    882\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstate_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    883\u001b[39m \u001b[43m    \u001b[49m\u001b[43mamsgrad\u001b[49m\u001b[43m=\u001b[49m\u001b[43mamsgrad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    884\u001b[39m \u001b[43m    \u001b[49m\u001b[43mhas_complex\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhas_complex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    885\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbeta1\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbeta1\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    886\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbeta2\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbeta2\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    887\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlr\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    888\u001b[39m \u001b[43m    \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[43m=\u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    889\u001b[39m \u001b[43m    \u001b[49m\u001b[43meps\u001b[49m\u001b[43m=\u001b[49m\u001b[43meps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    890\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmaximize\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmaximize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    891\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcapturable\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcapturable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    892\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdifferentiable\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdifferentiable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    893\u001b[39m \u001b[43m    \u001b[49m\u001b[43mgrad_scale\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgrad_scale\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    894\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfound_inf\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfound_inf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    895\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/dl_project/lib/python3.12/site-packages/torch/optim/adam.py:705\u001b[39m, in \u001b[36m_multi_tensor_adam\u001b[39m\u001b[34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, grad_scale, found_inf, amsgrad, has_complex, beta1, beta2, lr, weight_decay, eps, maximize, capturable, differentiable)\u001b[39m\n\u001b[32m    702\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    703\u001b[39m     exp_avg_sq_sqrt = torch._foreach_sqrt(device_exp_avg_sqs)\n\u001b[32m--> \u001b[39m\u001b[32m705\u001b[39m \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_foreach_div_\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexp_avg_sq_sqrt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias_correction2_sqrt\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    706\u001b[39m torch._foreach_add_(exp_avg_sq_sqrt, eps)\n\u001b[32m    707\u001b[39m torch._foreach_addcdiv_(\n\u001b[32m    708\u001b[39m     device_params, device_exp_avgs, exp_avg_sq_sqrt, step_size  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n\u001b[32m    709\u001b[39m )\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "# training loop for the model\n",
    "loss_history = []\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()  # change the mode to training, activating layers like DropOut and BatchNorm, if there are any\n",
    "    train_losses = []\n",
    "    \n",
    "    for features, targets in train_loader:\n",
    "        # send data to device\n",
    "        features = features.to(device)\n",
    "        targets = targets.to(device)\n",
    "        \n",
    "        # forward pass\n",
    "        output = model(features)  # calls model.forward(features)\n",
    "        # loss\n",
    "        loss = train_criterion(output.view(-1), targets.view(-1))\n",
    "        # backward pass\n",
    "        optimizer.zero_grad()  # clean the gradients from previous iteration, clears the `tensor.grad` field (tensor.grad=0)\n",
    "        loss.backward()  # autograd backward to calculate gradients, assigns the `tensor.grad` field (e.g., tensor.grad=0.27)\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)  # â† Gradient clipping\n",
    "        optimizer.step()  # apply update to the weights, applies the gradient update rule of the optimizer (param=param - lr * grad)\n",
    "        \n",
    "        train_losses.append(loss.item())\n",
    "    \n",
    "    model.eval()\n",
    "    val_losses = []\n",
    "    val_real_losses = []  # â† Better name\n",
    "    with torch.no_grad():\n",
    "        for features, targets in val_loader:\n",
    "            features = features.to(device)\n",
    "            targets = targets.to(device)\n",
    "            output = model(features)\n",
    "\n",
    "            loss = val_criterion(output.view(-1), targets.view(-1))\n",
    "            val_losses.append(loss.item())\n",
    "\n",
    "            real_output = torch.expm1(output)      # â† Changed from exp() to expm1()\n",
    "            real_targets = torch.expm1(targets)    # â† Changed from exp() to expm1()\n",
    "            real_loss = val_criterion(real_output.view(-1), real_targets.view(-1))\n",
    "            val_real_losses.append(real_loss.item())            \n",
    "    \n",
    "        train_loss = np.mean(train_losses)\n",
    "        val_loss = np.mean(val_losses)\n",
    "        val_real_loss  = np.mean(val_real_losses)\n",
    "        val_real_rmse = np.sqrt(val_real_loss)\n",
    "        scheduler.step(val_real_rmse)\n",
    "        loss_history.append((train_loss, val_loss, val_real_loss))\n",
    "\n",
    "    if epoch % 5 == 0:\n",
    "        print(f'Epoch {epoch}: Train Loss = {train_loss:.6f}, '\n",
    "              f'Val Loss (log) = {val_loss:.6f}, '\n",
    "              f'Val RMSE (real $) = ${val_real_rmse:,.2f}, '\n",
    "              f'LR={scheduler.get_last_lr()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9d77130",
   "metadata": {},
   "source": [
    "# Optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06aa7059",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader, TensorDataset\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import json\n",
    "import os\n",
    "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error\n",
    "import time\n",
    "import optuna\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "RANDOM_SEED = 50\n",
    "torch.manual_seed(RANDOM_SEED)\n",
    "np.random.seed(RANDOM_SEED)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed(RANDOM_SEED)\n",
    "\n",
    "# Device configuration\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68739d05",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DiamondPriceMLP(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dims, dropout_rate=0.3, use_batch_norm=True, target_mean=None):\n",
    "        super(DiamondPriceMLP, self).__init__()\n",
    "        \n",
    "        layers = []\n",
    "        prev_dim = input_dim\n",
    "        \n",
    "        for hidden_dim in hidden_dims:\n",
    "            layers.append(nn.Linear(prev_dim, hidden_dim))\n",
    "            \n",
    "            if use_batch_norm:\n",
    "                layers.append(nn.BatchNorm1d(hidden_dim))\n",
    "            \n",
    "            layers.append(nn.ReLU())\n",
    "            layers.append(nn.Dropout(dropout_rate))\n",
    "            \n",
    "            prev_dim = hidden_dim\n",
    "        \n",
    "        layers.append(nn.Linear(prev_dim, 1))\n",
    "        self.network = nn.Sequential(*layers)\n",
    "        \n",
    "        self._initialize_weights(target_mean)\n",
    "    \n",
    "    def _initialize_weights(self, target_mean):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Linear):\n",
    "                nn.init.kaiming_normal_(m.weight, mode='fan_in', nonlinearity='relu')\n",
    "                if m.bias is not None:\n",
    "                    nn.init.constant_(m.bias, 0)\n",
    "            elif isinstance(m, nn.BatchNorm1d):\n",
    "                nn.init.constant_(m.weight, 1)\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "        if target_mean is not None:\n",
    "            nn.init.constant_(self.network[-1].bias, target_mean)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.network(x).squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0430144c",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'y_train_log' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m np.std(\u001b[43my_train_log\u001b[49m)/\u001b[32m2\u001b[39m\n",
      "\u001b[31mNameError\u001b[39m: name 'y_train_log' is not defined"
     ]
    }
   ],
   "source": [
    "np.std(y_train_log)/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebfa13e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.load('data/X_train_final.npy')\n",
    "y_train_log = np.load('data/y_train_log.npy')\n",
    "X_val = np.load('data/X_val_final.npy')\n",
    "y_val_log = np.load('data/y_val_log.npy')\n",
    "\n",
    "def train_model(trial, X_train, y_train, X_val, y_val, device, \n",
    "                n_epochs=300, early_stopping_patience=40, early_stopping=False):\n",
    "    \"\"\"\n",
    "    Train model with hyperparameters suggested by Optuna\n",
    "    \n",
    "    Returns validation RMSE (lower is better)\n",
    "    \"\"\"\n",
    "    \n",
    "    # ========================================================================\n",
    "    # HYPERPARAMETERS TO TUNE\n",
    "    # ========================================================================\n",
    "    \n",
    "    # 1. Architecture\n",
    "    '''\n",
    "    n_layers = trial.suggest_int('n_layers', 3, 6)\n",
    "    hidden_dims = []\n",
    "    current_dim = trial.suggest_categorical('start_units', [1024, 256, 512])\n",
    "\n",
    "    for i in range(n_layers):\n",
    "        # FIX: Suggest a 'shrink' decision (0 = same size, 1 = half size)\n",
    "        # The choices [0, 1] are now STATIC, so Optuna stays happy.\n",
    "        should_shrink = trial.suggest_categorical(f'shrink_layer_{i}', [0, 1])\n",
    "        \n",
    "        if should_shrink == 1 and current_dim > 64: # Safety floor\n",
    "            current_dim = current_dim // 2\n",
    "            \n",
    "        hidden_dims.append(current_dim)\n",
    "    '''\n",
    "    hidden_dims = [512, 256, 256, 128, 128, 64, 32]\n",
    "    \n",
    "    # 2. Regularization\n",
    "    dropout_rate = trial.suggest_float('dropout_rate', 0.0, 0.5)\n",
    "    weight_decay = trial.suggest_float('weight_decay', 1e-6, 1e-3, log=True)\n",
    "    use_batch_norm = trial.suggest_categorical('use_batch_norm', [True, False])\n",
    "    \n",
    "    # 3. Learning rate\n",
    "    learning_rate = trial.suggest_float('learning_rate', 1e-5, 1e-2, log=True)\n",
    "    \n",
    "    # 4. Batch size\n",
    "    batch_size = trial.suggest_categorical('batch_size', [128, 256, 512])\n",
    "    \n",
    "    # ========================================================================\n",
    "    # CREATE MODEL AND OPTIMIZER\n",
    "    # ========================================================================\n",
    "    \n",
    "    model = DiamondPriceMLP(\n",
    "        input_dim=X_train.shape[1],\n",
    "        hidden_dims=hidden_dims,\n",
    "        dropout_rate=dropout_rate,\n",
    "        use_batch_norm=use_batch_norm,\n",
    "        target_mean=np.mean(y_train_log)\n",
    "    ).to(device)\n",
    "    \n",
    "\n",
    "    optimizer = torch.optim.Adam(\n",
    "        model.parameters(), \n",
    "        lr=learning_rate, \n",
    "        weight_decay=weight_decay\n",
    "    )\n",
    "\n",
    "    train_criterion = nn.HuberLoss(delta=trial.suggest_float('huber_delta', 0.05, 1.0))\n",
    "    val_criterion = nn.MSELoss()\n",
    "    \n",
    "    # Create dataloaders\n",
    "    train_dataset = TensorDataset(\n",
    "        torch.FloatTensor(X_train),\n",
    "        torch.FloatTensor(y_train)\n",
    "    )\n",
    "    val_dataset = TensorDataset(\n",
    "        torch.FloatTensor(X_val),\n",
    "        torch.FloatTensor(y_val)\n",
    "    )\n",
    "    \n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "    \n",
    "    # ========================================================================\n",
    "    # TRAINING LOOP\n",
    "    # ========================================================================\n",
    "    \n",
    "    best_val_rmse = float('inf')\n",
    "    patience_counter = 0\n",
    "    \n",
    "    for epoch in range(n_epochs):\n",
    "        # Train\n",
    "        model.train()\n",
    "        for features, targets in train_loader:\n",
    "            features = features.to(device)\n",
    "            targets = targets.to(device)\n",
    "            \n",
    "            output = model(features)\n",
    "            loss = train_criterion(output.view(-1), targets.view(-1))\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)  # â† Gradient clipping\n",
    "            \n",
    "            optimizer.step()\n",
    "        \n",
    "        # Validate\n",
    "        model.eval()\n",
    "        val_losses = []\n",
    "        val_real_losses = []\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for features, targets in val_loader:\n",
    "                features = features.to(device)\n",
    "                targets = targets.to(device)\n",
    "                \n",
    "                output = model(features)\n",
    "                loss = val_criterion(output.view(-1), targets.view(-1))\n",
    "                val_losses.append(loss.item())\n",
    "\n",
    "                real_output = torch.expm1(output)      # â† Changed from exp() to expm1()\n",
    "                real_targets = torch.expm1(targets)    # â† Changed from exp() to expm1()\n",
    "                real_loss = val_criterion(real_output.view(-1), real_targets.view(-1))\n",
    "                val_real_losses.append(real_loss.item())   \n",
    "        \n",
    "        val_loss = np.mean(val_losses)\n",
    "        val_real_loss  = np.mean(val_real_losses)\n",
    "        val_real_rmse = np.sqrt(val_real_loss)\n",
    "        \n",
    "        if val_real_rmse < best_val_rmse:\n",
    "                    best_val_rmse = val_real_rmse\n",
    "                    patience_counter = 0\n",
    "                    # Optional: Save best model state here\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "\n",
    "        # Report intermediate value for pruning\n",
    "        trial.report(val_real_rmse, epoch)\n",
    "        \n",
    "        if early_stopping and patience_counter >= early_stopping_patience:\n",
    "            print(f\"Early stopping at epoch {epoch}\")\n",
    "            break\n",
    "\n",
    "        # Prune unpromising trials\n",
    "        if trial.should_prune():\n",
    "            raise optuna.TrialPruned()\n",
    "    \n",
    "    # ========================================================================\n",
    "    # FINAL EVALUATION (Real RMSE)\n",
    "    # ========================================================================\n",
    "    \n",
    "    model.eval()\n",
    "    total_real_mse = 0.0\n",
    "    total_samples = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for features, targets in val_loader:\n",
    "            features = features.to(device)\n",
    "            targets = targets.to(device)\n",
    "            \n",
    "            # 1. Get model log-predictions\n",
    "            output_log = model(features).view(-1)\n",
    "            targets_log = targets.view(-1)\n",
    "            \n",
    "            # 2. Transform BOTH to real prices ($)\n",
    "            # We do this before the criterion to calculate RMSE in dollars\n",
    "            output_real = torch.expm1(output_log)\n",
    "            targets_real = torch.expm1(targets_log)\n",
    "            \n",
    "            # 3. Calculate MSE for this batch in real dollars\n",
    "            # val_criterion is nn.MSELoss()\n",
    "            batch_mse = val_criterion(output_real, targets_real)\n",
    "            \n",
    "            # 4. Accumulate weighted by batch size (handles smaller last batches)\n",
    "            batch_size = features.size(0)\n",
    "            total_real_mse += batch_mse.item() * batch_size\n",
    "            total_samples += batch_size\n",
    "\n",
    "    # 5. Final RMSE calculation\n",
    "    final_real_mse = total_real_mse / total_samples\n",
    "    rmse = np.sqrt(final_real_mse)\n",
    "    \n",
    "    return rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7245df0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def objective(trial):\n",
    "    \"\"\"\n",
    "    Objective function for Optuna to minimize\n",
    "    \"\"\"\n",
    "    \n",
    "    # Load data\n",
    "    print(f\"\\nTrial {trial.number}: Testing hyperparameters...\")\n",
    "    \n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    \n",
    "    # Train and evaluate\n",
    "    try:\n",
    "        rmse = train_model(trial, X_train, y_train_log, X_val, y_val_log, device, early_stopping=False)\n",
    "        \n",
    "        # Check for invalid values\n",
    "        if np.isnan(rmse) or np.isinf(rmse):\n",
    "            rmse = 1e10 # Large penalty\n",
    "    \n",
    "    except Exception as e:\n",
    "            print(f\"Trial failed due to: {e}\")\n",
    "            rmse = 1e10\n",
    "  \n",
    "    print(f\"  â†’ Validation RMSE: ${rmse:,.0f}\")\n",
    "    \n",
    "    return rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e591ebd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2026-01-09 13:20:50,883] A new study created in memory with name: diamond-mlp\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e4d0fea75cbc46babe86aeb6787752d5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Trial 0: Testing hyperparameters...\n",
      "  â†’ Validation RMSE: $11,961,492,460\n",
      "[I 2026-01-09 13:33:04,845] Trial 0 finished with value: 11961492460.215551 and parameters: {'dropout_rate': 0.18727005942368125, 'weight_decay': 0.0007114476009343421, 'learning_rate': 0.0029106359131330704, 'batch_size': 128, 'huber_delta': 0.10517943155978948}. Best is trial 0 with value: 11961492460.215551.\n",
      "\n",
      "Trial 1: Testing hyperparameters...\n",
      "[W 2026-01-09 13:33:38,449] Trial 1 failed with parameters: {'dropout_rate': 0.4330880728874676, 'weight_decay': 6.358358856676247e-05, 'learning_rate': 0.0026070247583707684, 'batch_size': 256, 'huber_delta': 0.25172215514436236} because of the following error: KeyboardInterrupt().\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/amit.ru/miniconda3/envs/dl_project/lib/python3.12/site-packages/optuna/study/_optimize.py\", line 205, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "                      ^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_1402892/2401057943.py\", line 13, in objective\n",
      "    rmse = train_model(trial, X_train, y_train_log, X_val, y_val_log, device, early_stopping=False)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_1402892/2009921152.py\", line 92, in train_model\n",
      "    for features, targets in train_loader:\n",
      "                             ^^^^^^^^^^^^\n",
      "  File \"/home/amit.ru/miniconda3/envs/dl_project/lib/python3.12/site-packages/torch/utils/data/dataloader.py\", line 708, in __next__\n",
      "    data = self._next_data()\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/amit.ru/miniconda3/envs/dl_project/lib/python3.12/site-packages/torch/utils/data/dataloader.py\", line 764, in _next_data\n",
      "    data = self._dataset_fetcher.fetch(index)  # may raise StopIteration\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/amit.ru/miniconda3/envs/dl_project/lib/python3.12/site-packages/torch/utils/data/_utils/fetch.py\", line 55, in fetch\n",
      "    return self.collate_fn(data)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/amit.ru/miniconda3/envs/dl_project/lib/python3.12/site-packages/torch/utils/data/_utils/collate.py\", line 398, in default_collate\n",
      "    return collate(batch, collate_fn_map=default_collate_fn_map)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/amit.ru/miniconda3/envs/dl_project/lib/python3.12/site-packages/torch/utils/data/_utils/collate.py\", line 158, in collate\n",
      "    if isinstance(elem, collate_type):\n",
      "       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "KeyboardInterrupt\n",
      "[W 2026-01-09 13:33:38,451] Trial 1 failed with value None.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      2\u001b[39m sampler = optuna.samplers.TPESampler(seed=\u001b[32m42\u001b[39m)\n\u001b[32m      3\u001b[39m study = optuna.create_study(study_name=\u001b[33m\"\u001b[39m\u001b[33mdiamond-mlp\u001b[39m\u001b[33m\"\u001b[39m, direction=\u001b[33m\"\u001b[39m\u001b[33mminimize\u001b[39m\u001b[33m\"\u001b[39m, sampler=sampler)\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m \u001b[43mstudy\u001b[49m\u001b[43m.\u001b[49m\u001b[43moptimize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobjective\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m100\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshow_progress_bar\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m      6\u001b[39m pruned_trials = [t \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m study.trials \u001b[38;5;28;01mif\u001b[39;00m t.state == optuna.trial.TrialState.PRUNED]\n\u001b[32m      7\u001b[39m complete_trials = [t \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m study.trials \u001b[38;5;28;01mif\u001b[39;00m t.state == optuna.trial.TrialState.COMPLETE]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/dl_project/lib/python3.12/site-packages/optuna/study/study.py:490\u001b[39m, in \u001b[36mStudy.optimize\u001b[39m\u001b[34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[39m\n\u001b[32m    388\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34moptimize\u001b[39m(\n\u001b[32m    389\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    390\u001b[39m     func: ObjectiveFuncType,\n\u001b[32m   (...)\u001b[39m\u001b[32m    397\u001b[39m     show_progress_bar: \u001b[38;5;28mbool\u001b[39m = \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[32m    398\u001b[39m ) -> \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    399\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Optimize an objective function.\u001b[39;00m\n\u001b[32m    400\u001b[39m \n\u001b[32m    401\u001b[39m \u001b[33;03m    Optimization is done by choosing a suitable set of hyperparameter values from a given\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    488\u001b[39m \u001b[33;03m            If nested invocation of this method occurs.\u001b[39;00m\n\u001b[32m    489\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m490\u001b[39m     \u001b[43m_optimize\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    491\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    492\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    493\u001b[39m \u001b[43m        \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m=\u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    494\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    495\u001b[39m \u001b[43m        \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    496\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mtuple\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43misinstance\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mIterable\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    497\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    498\u001b[39m \u001b[43m        \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    499\u001b[39m \u001b[43m        \u001b[49m\u001b[43mshow_progress_bar\u001b[49m\u001b[43m=\u001b[49m\u001b[43mshow_progress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    500\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/dl_project/lib/python3.12/site-packages/optuna/study/_optimize.py:67\u001b[39m, in \u001b[36m_optimize\u001b[39m\u001b[34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[39m\n\u001b[32m     65\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m     66\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m n_jobs == \u001b[32m1\u001b[39m:\n\u001b[32m---> \u001b[39m\u001b[32m67\u001b[39m         \u001b[43m_optimize_sequential\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     68\u001b[39m \u001b[43m            \u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     69\u001b[39m \u001b[43m            \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     70\u001b[39m \u001b[43m            \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     71\u001b[39m \u001b[43m            \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     72\u001b[39m \u001b[43m            \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     73\u001b[39m \u001b[43m            \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     74\u001b[39m \u001b[43m            \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     75\u001b[39m \u001b[43m            \u001b[49m\u001b[43mreseed_sampler_rng\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m     76\u001b[39m \u001b[43m            \u001b[49m\u001b[43mtime_start\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m     77\u001b[39m \u001b[43m            \u001b[49m\u001b[43mprogress_bar\u001b[49m\u001b[43m=\u001b[49m\u001b[43mprogress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     78\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     79\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m     80\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m n_jobs == -\u001b[32m1\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/dl_project/lib/python3.12/site-packages/optuna/study/_optimize.py:164\u001b[39m, in \u001b[36m_optimize_sequential\u001b[39m\u001b[34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001b[39m\n\u001b[32m    161\u001b[39m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[32m    163\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m164\u001b[39m     frozen_trial_id = \u001b[43m_run_trial\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    165\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    166\u001b[39m     \u001b[38;5;66;03m# The following line mitigates memory problems that can be occurred in some\u001b[39;00m\n\u001b[32m    167\u001b[39m     \u001b[38;5;66;03m# environments (e.g., services that use computing containers such as GitHub Actions).\u001b[39;00m\n\u001b[32m    168\u001b[39m     \u001b[38;5;66;03m# Please refer to the following PR for further details:\u001b[39;00m\n\u001b[32m    169\u001b[39m     \u001b[38;5;66;03m# https://github.com/optuna/optuna/pull/325.\u001b[39;00m\n\u001b[32m    170\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m gc_after_trial:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/dl_project/lib/python3.12/site-packages/optuna/study/_optimize.py:262\u001b[39m, in \u001b[36m_run_trial\u001b[39m\u001b[34m(study, func, catch)\u001b[39m\n\u001b[32m    255\u001b[39m         \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[33m\"\u001b[39m\u001b[33mShould not reach.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    257\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m    258\u001b[39m     updated_state == TrialState.FAIL\n\u001b[32m    259\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m func_err \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    260\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(func_err, catch)\n\u001b[32m    261\u001b[39m ):\n\u001b[32m--> \u001b[39m\u001b[32m262\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m func_err\n\u001b[32m    263\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m trial._trial_id\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/dl_project/lib/python3.12/site-packages/optuna/study/_optimize.py:205\u001b[39m, in \u001b[36m_run_trial\u001b[39m\u001b[34m(study, func, catch)\u001b[39m\n\u001b[32m    203\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m get_heartbeat_thread(trial._trial_id, study._storage):\n\u001b[32m    204\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m205\u001b[39m         value_or_values = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    206\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m exceptions.TrialPruned \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    207\u001b[39m         \u001b[38;5;66;03m# TODO(mamu): Handle multi-objective cases.\u001b[39;00m\n\u001b[32m    208\u001b[39m         state = TrialState.PRUNED\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 13\u001b[39m, in \u001b[36mobjective\u001b[39m\u001b[34m(trial)\u001b[39m\n\u001b[32m     11\u001b[39m \u001b[38;5;66;03m# Train and evaluate\u001b[39;00m\n\u001b[32m     12\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m13\u001b[39m     rmse = \u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train_log\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_val\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_val_log\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mearly_stopping\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m     15\u001b[39m     \u001b[38;5;66;03m# Check for invalid values\u001b[39;00m\n\u001b[32m     16\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m np.isnan(rmse) \u001b[38;5;129;01mor\u001b[39;00m np.isinf(rmse):\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 92\u001b[39m, in \u001b[36mtrain_model\u001b[39m\u001b[34m(trial, X_train, y_train, X_val, y_val, device, n_epochs, early_stopping_patience, early_stopping)\u001b[39m\n\u001b[32m     89\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(n_epochs):\n\u001b[32m     90\u001b[39m     \u001b[38;5;66;03m# Train\u001b[39;00m\n\u001b[32m     91\u001b[39m     model.train()\n\u001b[32m---> \u001b[39m\u001b[32m92\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mfeatures\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtargets\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m     93\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfeatures\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mfeatures\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     94\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtargets\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mtargets\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/dl_project/lib/python3.12/site-packages/torch/utils/data/dataloader.py:708\u001b[39m, in \u001b[36m_BaseDataLoaderIter.__next__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    705\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    706\u001b[39m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[32m    707\u001b[39m     \u001b[38;5;28mself\u001b[39m._reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m708\u001b[39m data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    709\u001b[39m \u001b[38;5;28mself\u001b[39m._num_yielded += \u001b[32m1\u001b[39m\n\u001b[32m    710\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m    711\u001b[39m     \u001b[38;5;28mself\u001b[39m._dataset_kind == _DatasetKind.Iterable\n\u001b[32m    712\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    713\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._num_yielded > \u001b[38;5;28mself\u001b[39m._IterableDataset_len_called\n\u001b[32m    714\u001b[39m ):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/dl_project/lib/python3.12/site-packages/torch/utils/data/dataloader.py:764\u001b[39m, in \u001b[36m_SingleProcessDataLoaderIter._next_data\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    762\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m    763\u001b[39m     index = \u001b[38;5;28mself\u001b[39m._next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m764\u001b[39m     data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[32m    765\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._pin_memory:\n\u001b[32m    766\u001b[39m         data = _utils.pin_memory.pin_memory(data, \u001b[38;5;28mself\u001b[39m._pin_memory_device)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/dl_project/lib/python3.12/site-packages/torch/utils/data/_utils/fetch.py:55\u001b[39m, in \u001b[36m_MapDatasetFetcher.fetch\u001b[39m\u001b[34m(self, possibly_batched_index)\u001b[39m\n\u001b[32m     53\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m     54\u001b[39m     data = \u001b[38;5;28mself\u001b[39m.dataset[possibly_batched_index]\n\u001b[32m---> \u001b[39m\u001b[32m55\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcollate_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/dl_project/lib/python3.12/site-packages/torch/utils/data/_utils/collate.py:398\u001b[39m, in \u001b[36mdefault_collate\u001b[39m\u001b[34m(batch)\u001b[39m\n\u001b[32m    337\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mdefault_collate\u001b[39m(batch):\n\u001b[32m    338\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33mr\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    339\u001b[39m \u001b[33;03m    Take in a batch of data and put the elements within the batch into a tensor with an additional outer dimension - batch size.\u001b[39;00m\n\u001b[32m    340\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m    396\u001b[39m \u001b[33;03m        >>> default_collate(batch)  # Handle `CustomType` automatically\u001b[39;00m\n\u001b[32m    397\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m398\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcollate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcollate_fn_map\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdefault_collate_fn_map\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/dl_project/lib/python3.12/site-packages/torch/utils/data/_utils/collate.py:158\u001b[39m, in \u001b[36mcollate\u001b[39m\u001b[34m(batch, collate_fn_map)\u001b[39m\n\u001b[32m    155\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m collate_fn_map[elem_type](batch, collate_fn_map=collate_fn_map)\n\u001b[32m    157\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m collate_type \u001b[38;5;129;01min\u001b[39;00m collate_fn_map:\n\u001b[32m--> \u001b[39m\u001b[32m158\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(elem, collate_type):\n\u001b[32m    159\u001b[39m             \u001b[38;5;28;01mreturn\u001b[39;00m collate_fn_map[collate_type](\n\u001b[32m    160\u001b[39m                 batch, collate_fn_map=collate_fn_map\n\u001b[32m    161\u001b[39m             )\n\u001b[32m    163\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(elem, collections.abc.Mapping):\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "# now we can run the experiment\n",
    "sampler = optuna.samplers.TPESampler(seed=42)\n",
    "study = optuna.create_study(study_name=\"diamond-mlp\", direction=\"minimize\", sampler=sampler)\n",
    "study.optimize(objective, n_trials=100, show_progress_bar=True)\n",
    "\n",
    "pruned_trials = [t for t in study.trials if t.state == optuna.trial.TrialState.PRUNED]\n",
    "complete_trials = [t for t in study.trials if t.state == optuna.trial.TrialState.COMPLETE]\n",
    "\n",
    "print(\"Study statistics: \")\n",
    "print(\"  Number of finished trials: \", len(study.trials))\n",
    "print(\"  Number of pruned trials: \", len(pruned_trials))\n",
    "print(\"  Number of complete trials: \", len(complete_trials))\n",
    "\n",
    "print(\"Best trial:\")\n",
    "trial = study.best_trial\n",
    "\n",
    "print(\"  Value: \", trial.value)\n",
    "\n",
    "print(\"  Params: \")\n",
    "for key, value in trial.params.items():\n",
    "    print(\"    {}: {}\".format(key, value))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dl_project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
