{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "TGQ50FtzzTWd"
      },
      "outputs": [],
      "source": [
        "import kagglehub\n",
        "from kagglehub import KaggleDatasetAdapter\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler, MinMaxScaler, OneHotEncoder\n",
        "from scipy import stats\n",
        "import pickle\n",
        "import json\n",
        "from pathlib import Path"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N6NT9aJmWnp2",
        "outputId": "9796231b-7f3d-4577-8ff6-da8c6236d213"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading dataset...\n",
            "\n",
            "================================================================================\n",
            "DATASET OVERVIEW\n",
            "================================================================================\n",
            "Shape: 219703 rows × 26 columns\n",
            "\n",
            "Columns: ['Unnamed: 0', 'cut', 'color', 'clarity', 'carat_weight', 'cut_quality', 'lab', 'symmetry', 'polish', 'eye_clean', 'culet_size', 'culet_condition', 'depth_percent', 'table_percent', 'meas_length', 'meas_width', 'meas_depth', 'girdle_min', 'girdle_max', 'fluor_color', 'fluor_intensity', 'fancy_color_dominant_color', 'fancy_color_secondary_color', 'fancy_color_overtone', 'fancy_color_intensity', 'total_sales_price']\n",
            "\n",
            "Data types:\n",
            "Unnamed: 0                       int64\n",
            "cut                             object\n",
            "color                           object\n",
            "clarity                         object\n",
            "carat_weight                   float64\n",
            "cut_quality                     object\n",
            "lab                             object\n",
            "symmetry                        object\n",
            "polish                          object\n",
            "eye_clean                       object\n",
            "culet_size                      object\n",
            "culet_condition                 object\n",
            "depth_percent                  float64\n",
            "table_percent                  float64\n",
            "meas_length                    float64\n",
            "meas_width                     float64\n",
            "meas_depth                     float64\n",
            "girdle_min                      object\n",
            "girdle_max                      object\n",
            "fluor_color                     object\n",
            "fluor_intensity                 object\n",
            "fancy_color_dominant_color      object\n",
            "fancy_color_secondary_color     object\n",
            "fancy_color_overtone            object\n",
            "fancy_color_intensity           object\n",
            "total_sales_price                int64\n",
            "dtype: object\n",
            "\n",
            "Missing values:\n",
            "Unnamed: 0                          0\n",
            "cut                                 0\n",
            "color                               0\n",
            "clarity                             0\n",
            "carat_weight                        0\n",
            "cut_quality                         0\n",
            "lab                                 0\n",
            "symmetry                            0\n",
            "polish                              0\n",
            "eye_clean                           0\n",
            "culet_size                          0\n",
            "culet_condition                     0\n",
            "depth_percent                       0\n",
            "table_percent                       0\n",
            "meas_length                         0\n",
            "meas_width                          0\n",
            "meas_depth                          0\n",
            "girdle_min                          0\n",
            "girdle_max                          0\n",
            "fluor_color                         0\n",
            "fluor_intensity                143491\n",
            "fancy_color_dominant_color          0\n",
            "fancy_color_secondary_color         0\n",
            "fancy_color_overtone             1650\n",
            "fancy_color_intensity               0\n",
            "total_sales_price                   0\n",
            "dtype: int64\n",
            "\n",
            "\n",
            "Categorical columns: ['cut', 'color', 'clarity', 'cut_quality', 'lab', 'symmetry', 'polish', 'eye_clean', 'culet_size', 'culet_condition', 'girdle_min', 'girdle_max', 'fluor_color', 'fluor_intensity', 'fancy_color_dominant_color', 'fancy_color_secondary_color', 'fancy_color_overtone', 'fancy_color_intensity']\n",
            "Numerical columns: ['Unnamed: 0', 'carat_weight', 'depth_percent', 'table_percent', 'meas_length', 'meas_width', 'meas_depth', 'total_sales_price']\n"
          ]
        }
      ],
      "source": [
        "# Load the dataset\n",
        "print(\"Loading dataset...\")\n",
        "dataset_handle = \"hrokrin/the-largest-diamond-dataset-currely-on-kaggle\"\n",
        "filename = \"diamonds.csv\"\n",
        "\n",
        "df = kagglehub.dataset_load(\n",
        "    KaggleDatasetAdapter.PANDAS,\n",
        "    dataset_handle,\n",
        "    filename,\n",
        ")\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"DATASET OVERVIEW\")\n",
        "print(\"=\"*80)\n",
        "print(f\"Shape: {df.shape[0]} rows × {df.shape[1]} columns\")\n",
        "print(f\"\\nColumns: {df.columns.tolist()}\")\n",
        "print(f\"\\nData types:\\n{df.dtypes}\")\n",
        "print(f\"\\nMissing values:\\n{df.isnull().sum()}\")\n",
        "\n",
        "# Separate numerical and categorical columns\n",
        "categorical_cols = df.select_dtypes(include=['object']).columns.tolist()\n",
        "numerical_cols = df.select_dtypes(include=[np.number]).columns.tolist()\n",
        "\n",
        "print(f\"\\n\\nCategorical columns: {categorical_cols}\")\n",
        "print(f\"Numerical columns: {numerical_cols}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "ntnVJlyO0B7o"
      },
      "outputs": [],
      "source": [
        "df = df[(df['meas_length'] > 0) & (df['meas_width'] > 0) & (df['meas_depth'] > 0) & (df['total_sales_price'] > 0)]\n",
        "features = ['cut', 'color', 'clarity', 'carat_weight', 'cut_quality', 'clarity',\n",
        "            'polish', 'symmetry', 'meas_length', 'meas_width', 'meas_depth']\n",
        "\n",
        "X = df[features]\n",
        "y = df['total_sales_price']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jq2vQOSQ54O0",
        "outputId": "9cfc3f27-d341-4005-a790-649ef7960e56"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "================================================================================\n",
            "DATASET OVERVIEW\n",
            "================================================================================\n",
            "Shape: 217910 rows × 11 columns\n",
            "\n",
            "Columns: ['cut', 'color', 'clarity', 'carat_weight', 'cut_quality', 'clarity', 'polish', 'symmetry', 'meas_length', 'meas_width', 'meas_depth']\n",
            "\n",
            "Data types:\n",
            "cut              object\n",
            "color            object\n",
            "clarity          object\n",
            "carat_weight    float64\n",
            "cut_quality      object\n",
            "clarity          object\n",
            "polish           object\n",
            "symmetry         object\n",
            "meas_length     float64\n",
            "meas_width      float64\n",
            "meas_depth      float64\n",
            "dtype: object\n",
            "\n",
            "\n",
            "Categorical columns: ['cut', 'color', 'clarity', 'cut_quality', 'clarity', 'polish', 'symmetry']\n",
            "Numerical columns: ['carat_weight', 'meas_length', 'meas_width', 'meas_depth']\n"
          ]
        }
      ],
      "source": [
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"DATASET OVERVIEW\")\n",
        "print(\"=\"*80)\n",
        "print(f\"Shape: {X.shape[0]} rows × {X.shape[1]} columns\")\n",
        "print(f\"\\nColumns: {X.columns.tolist()}\")\n",
        "print(f\"\\nData types:\\n{X.dtypes}\")\n",
        "\n",
        "# Separate numerical and categorical columns\n",
        "categorical_cols = X.select_dtypes(include=['object']).columns.tolist()\n",
        "numerical_cols = X.select_dtypes(include=[np.number]).columns.tolist()\n",
        "\n",
        "print(f\"\\n\\nCategorical columns: {categorical_cols}\")\n",
        "print(f\"Numerical columns: {numerical_cols}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "0GM9kIyV9YEM"
      },
      "outputs": [],
      "source": [
        "# 3. Split data\n",
        "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.3, random_state=44)\n",
        "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=44)\n",
        "\n",
        "# 4. Transform target to log\n",
        "y_train_log = np.log1p(y_train)\n",
        "y_val_log = np.log1p(y_val)\n",
        "y_test_log = np.log1p(y_test)\n",
        "\n",
        "# 5. Scale numerical features (fit on train only!)\n",
        "numerical_cols = ['carat_weight', 'meas_length', 'meas_width', 'meas_depth']\n",
        "scaler = StandardScaler()\n",
        "X_train[numerical_cols] = scaler.fit_transform(X_train[numerical_cols])\n",
        "X_val[numerical_cols] = scaler.transform(X_val[numerical_cols])\n",
        "X_test[numerical_cols] = scaler.transform(X_test[numerical_cols])\n",
        "\n",
        "# 6. One-hot encode categorical (fit on train only!)\n",
        "categorical_cols = ['cut', 'color', 'clarity', 'cut_quality', 'polish', 'symmetry']\n",
        "encoder = OneHotEncoder(sparse_output=False, drop='first', handle_unknown='ignore')\n",
        "encoder.fit(X_train[categorical_cols])\n",
        "\n",
        "# 7. Combine features\n",
        "X_train_final = np.hstack([\n",
        "    X_train[numerical_cols].values,\n",
        "    encoder.transform(X_train[categorical_cols])\n",
        "])\n",
        "\n",
        "X_val_final = np.hstack([\n",
        "    X_val[numerical_cols].values,\n",
        "    encoder.transform(X_val[categorical_cols])\n",
        "])\n",
        "\n",
        "X_test_final = np.hstack([\n",
        "    X_test[numerical_cols].values,\n",
        "    encoder.transform(X_test[categorical_cols])\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CK_uk7hF-rJM",
        "outputId": "4b9dba65-c4ce-4fc4-ebdb-002dcb844120"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Saving preprocessed data...\n",
            "✓ All data saved to: /home/amit.ru/Documents/DL-Project/src/mlp_part/data/\n"
          ]
        }
      ],
      "source": [
        "# Create output directory\n",
        "output_dir = Path.cwd().resolve() \n",
        "output_dir.mkdir(exist_ok=True)\n",
        "\n",
        "print(\"\\nSaving preprocessed data...\")\n",
        "\n",
        "# Save arrays\n",
        "np.save(output_dir / 'X_train_final.npy', X_train_final)\n",
        "np.save(output_dir / 'X_val_final.npy', X_val_final)\n",
        "np.save(output_dir / 'X_test_final.npy', X_test_final)\n",
        "\n",
        "np.save(output_dir / 'y_train_raw.npy', y_train.values)\n",
        "np.save(output_dir / 'y_val_raw.npy', y_val.values)\n",
        "np.save(output_dir / 'y_test_raw.npy', y_test.values)\n",
        "\n",
        "np.save(output_dir / 'y_train_log.npy', y_train_log.values)\n",
        "np.save(output_dir / 'y_val_log.npy', y_val_log.values)\n",
        "np.save(output_dir / 'y_test_log.npy', y_test_log.values)\n",
        "\n",
        "# Save preprocessors\n",
        "with open(output_dir / 'scaler.pkl', 'wb') as f:\n",
        "    pickle.dump(scaler, f)\n",
        "with open(output_dir / 'encoder.pkl', 'wb') as f:\n",
        "    pickle.dump(encoder, f)\n",
        "\n",
        "# Save metadata\n",
        "ohe_feature_names = encoder.get_feature_names_out().tolist()\n",
        "metadata = {\n",
        "    'numerical_features': numerical_cols,\n",
        "    'categorical_features': categorical_cols,\n",
        "    'final_feature_names': numerical_cols + ohe_feature_names,\n",
        "    'n_features': X_train_final.shape[1],\n",
        "    'n_train': len(X_train_final),\n",
        "    'n_val': len(X_val_final),\n",
        "    'n_test': len(X_test_final),\n",
        "}\n",
        "with open(output_dir / 'metadata.json', 'w') as f:\n",
        "    json.dump(metadata, f, indent=2)\n",
        "\n",
        "print(f\"✓ All data saved to: {output_dir}/\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load features and targets\n",
        "X_train = np.load('X_train_final.npy')\n",
        "X_val = np.load('X_val_final.npy')\n",
        "X_test = np.load('X_test_final.npy')\n",
        "\n",
        "y_train = np.load('y_train_log.npy')  # Use log version!\n",
        "y_val = np.load('y_val_log.npy')\n",
        "y_test = np.load('y_test_log.npy')"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "dl_project",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
